{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6uzDx9K2gz4",
        "outputId": "4c4058f8-ccba-4166-b00c-624494370abd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/drive/MyDrive/PRJ-3563_archive.zip'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUyB6NnL2vJY",
        "outputId": "1db77b0c-81eb-4eb8-a7b0-6affbdd5ec8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/PRJ-3563_archive.zip\n",
            " extracting: PRJ-3563/Ida-BD_description.pdf  \n",
            " extracting: PRJ-3563/images/AOI1-tile_10-6_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_7-6_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_1-3_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_4-5_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_6-3_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_2-3_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_4-3_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_4-6_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_5-2_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_6-3_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_6-2_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_11-3_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_1-0_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_6-5_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_6-5_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_6-4_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_3-4_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_9-5_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_2-3_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_5-3_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_3-4_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_11-4_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_5-6_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_4-3_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_4-4_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_2-9_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_2-4_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_9-3_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_7-5_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_2-4_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_1-8_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_2-6_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_1-10_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_2-9_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_9-6_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_6-4_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_11-5_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_9-4_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_5-2_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_8-3_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_1-4_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_4-2_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_2-6_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_2-1_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_3-4_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_5-2_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_9-7_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_5-5_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_1-1_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_3-5_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_11-3_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_5-4_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_1-4_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_9-4_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_4-4_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_11-4_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_8-4_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_2-3_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_6-6_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_6-1_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_10-5_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_6-2_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_10-3_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_4-5_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_8-8_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_10-4_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_7-4_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_9-6_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_2-1_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_1-4_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_4-6_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_5-6_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_8-2_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_3-2_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_5-6_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_8-4_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_7-2_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_5-3_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_10-4_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_4-4_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_1-0_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_7-4_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_6-4_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_10-5_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_4-5_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_2-4_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_1-2_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_5-3_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_5-4_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_7-5_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_6-4_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_5-7_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_7-6_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_5-3_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_5-5_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_8-8_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_4-2_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_3-3_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_1-9_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_7-4_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_1-4_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_7-1_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_2-5_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_3-1_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_7-4_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_5-6_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_9-5_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_1-9_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_6-3_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_8-3_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_1-10_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_7-3_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_6-1_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_3-1_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_6-6_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_4-1_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_2-2_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_1-1_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_7-6_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_10-3_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_7-5_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_6-6_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_3-3_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_2-5_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_4-2_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_5-4_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_6-5_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_3-5_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_7-6_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_3-6_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_6-2_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_4-5_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_5-4_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_4-6_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_11-5_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_4-3_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_3-5_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_5-7_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_1-3_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_9-2_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_6-3_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_2-3_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_9-2_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_4-3_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_7-2_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_3-5_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_7-3_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_7-5_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_8-5_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_5-2_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_9-7_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_4-1_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_2-2_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_4-4_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_6-2_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_5-5_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_8-5_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_4-6_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_2-4_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_6-6_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_4-2_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_1-8_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_3-4_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_5-5_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_8-2_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_1-2_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_3-6_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_6-5_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_7-1_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_9-3_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_3-3_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_3-3_post_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI1-tile_10-6_pre_disaster.png  \n",
            " extracting: PRJ-3563/images/AOI3-tile_3-2_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_10-6_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_7-6_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_1-3_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_4-5_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_6-3_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_2-3_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_4-3_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_4-6_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_5-2_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_6-3_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_6-2_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_11-3_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_1-0_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_6-5_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_6-5_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_6-4_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_3-4_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_9-5_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_2-3_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_5-3_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_3-4_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_11-4_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_5-6_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_4-3_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_4-4_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_2-9_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_2-4_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_9-3_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_7-5_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_2-4_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_1-8_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_2-6_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_1-10_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_2-9_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_9-6_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_6-4_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_11-5_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_9-4_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_5-2_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_8-3_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_1-4_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_4-2_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_2-6_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_2-1_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_3-4_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_5-2_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_9-7_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_5-5_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_1-1_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_3-5_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_11-3_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_5-4_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_1-4_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_9-4_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_4-4_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_11-4_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_8-4_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_2-3_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_6-6_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_6-1_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_10-5_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_6-2_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_10-3_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_4-5_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_8-8_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_10-4_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_7-4_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_9-6_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_2-1_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_1-4_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_4-6_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_5-6_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_8-2_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_3-2_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_5-6_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_8-4_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_7-2_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_5-3_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_10-4_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_4-4_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_1-0_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_7-4_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_6-4_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_10-5_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_4-5_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_2-4_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_1-2_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_5-3_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_5-4_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_7-5_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_6-4_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_5-7_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_7-6_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_5-3_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_5-5_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_8-8_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_4-2_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_3-3_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_1-9_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_7-4_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_1-4_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_7-1_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_2-5_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_3-1_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_7-4_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_5-6_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_9-5_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_1-9_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_6-3_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_8-3_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_1-10_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_7-3_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_6-1_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_3-1_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_6-6_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_4-1_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_2-2_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_1-1_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_7-6_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_10-3_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_7-5_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_6-6_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_3-3_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_2-5_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_4-2_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_5-4_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_6-5_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_3-5_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_7-6_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_3-6_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_6-2_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_4-5_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_5-4_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_4-6_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_11-5_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_4-3_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_3-5_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_5-7_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_1-3_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_9-2_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_6-3_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_2-3_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_9-2_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_4-3_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_7-2_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_3-5_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_7-3_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_7-5_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_8-5_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_5-2_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_9-7_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_4-1_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_2-2_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_4-4_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_6-2_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_5-5_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_8-5_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_4-6_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_2-4_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_6-6_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_4-2_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_1-8_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_3-4_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_5-5_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_8-2_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_1-2_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_3-6_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_6-5_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_7-1_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_9-3_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_3-3_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_3-3_post_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI1-tile_10-6_pre_disaster.png  \n",
            " extracting: PRJ-3563/masks/AOI3-tile_3-2_post_disaster.png  \n",
            " extracting: PRJ-3563_metadata.json  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_JlaAVrg2Ca9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5710e7ae-5f6f-4b51-fc25-62ed1ab62a33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hyperspectral images created successfully.\n",
            "Total hyperspectral images: 50\n",
            "Total labels: 50\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "def assign_label(image_name):\n",
        "    if \"post_disaster\" in image_name:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def create_dataset(images_folder):\n",
        "    dataset = []\n",
        "    for image_name in os.listdir(images_folder):\n",
        "        if image_name.endswith(('.jpg', '.jpeg', '.png')):\n",
        "            image_path = os.path.join(images_folder, image_name)\n",
        "            label = assign_label(image_name)\n",
        "            dataset.append((image_path, label))\n",
        "    return dataset\n",
        "\n",
        "def create_hyperspectral(dataset):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for image_path, label in dataset[:50]:\n",
        "        img = Image.open(image_path)\n",
        "        img_array = np.array(img)\n",
        "        images.append(img_array)\n",
        "        labels.append(label)\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "images_folder = \"PRJ-3563/images\"\n",
        "dataset = create_dataset(images_folder)\n",
        "X, y = create_hyperspectral(dataset)\n",
        "\n",
        "# Convert RGB images to hyperspectral images\n",
        "# def convert_to_hyperspectral(rgb_images):\n",
        "#     spectral_bands = []\n",
        "#     for img in rgb_images:\n",
        "#         red = img[:, :, 0]\n",
        "#         green = img[:, :, 1]\n",
        "#         blue = img[:, :, 2]\n",
        "#         spectral_bands.append([red, green, blue])\n",
        "\n",
        "#     print(np.array(spectral_bands).shape)\n",
        "#     return np.array(spectral_bands)\n",
        "\n",
        "# X = convert_to_hyperspectral(X)\n",
        "\n",
        "print(\"Hyperspectral images created successfully.\")\n",
        "print(\"Total hyperspectral images:\", len(X))\n",
        "print(\"Total labels:\", len(y))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "--dg5j-C32pQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def splitTrainTestSet(X, y, testRatio, randomState=345):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testRatio, random_state=randomState,\n",
        "                                                        stratify=y)\n",
        "    return X_train, X_test, y_train, y_test"
      ],
      "metadata": {
        "id": "CdlTTICm3Qia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJmMW0aU2Ca-"
      },
      "outputs": [],
      "source": [
        "Xtrain, Xtest, ytrain, ytest = splitTrainTestSet(X, y, 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tensorflow.keras.layers import Input, Conv2D, Reshape, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "S = X.shape[0]\n",
        "L = X.shape[1]\n",
        "output_units = 1\n",
        "\n",
        "input_layer = Input((L , L , 3))\n",
        "\n",
        "\n",
        "conv_layer1 = Conv2D(filters=8, kernel_size=(3, 3), activation='relu' , padding = 'same')(input_layer)\n",
        "# conv_layer2 = Conv2D(filters=16, kernel_size=(3, 3), activation='relu')(conv_layer1)\n",
        "# conv_layer3 = Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding = 'same')(conv_layer2)\n",
        "\n",
        "# conv2d_shape = conv_layer3.shape\n",
        "flatten_layer = Flatten()(conv_layer1)\n",
        "\n",
        "dense_layer1 = Dense(units=64, activation='relu')(flatten_layer)\n",
        "dense_layer1 = Dropout(0.4)(dense_layer1)\n",
        "dense_layer2 = Dense(units=32, activation='relu')(dense_layer1)\n",
        "dense_layer2 = Dropout(0.4)(dense_layer2)\n",
        "output_layer = Dense(units=output_units, activation='sigmoid')(dense_layer2)\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bHBHi2B6-4K",
        "outputId": "018715a3-1c69-46bf-99b4-d06d3c2c14de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_11 (InputLayer)       [(None, 1024, 1024, 3)]   0         \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 1024, 1024, 8)     224       \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (None, 8388608)           0         \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 64)                536870976 \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_15 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 536873313 (2.00 GB)\n",
            "Trainable params: 536873313 (2.00 GB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "y = keras.utils.to_categorical(y)\n",
        "y.shape"
      ],
      "metadata": {
        "id": "RX0IlmqJ47mg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1db9977-989b-4fdd-bf51-32b88fbeb6aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=0.001,\n",
        "    decay_steps=10000,\n",
        "    decay_rate=0.9)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "wfrxYRwZ82Lg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ytrain = keras.utils.to_categorical(ytrain)\n",
        "# ytrain.shape\n",
        "\n",
        "# ytest = keras.utils.to_categorical(ytest)\n",
        "# y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4S6gvAp9bc5",
        "outputId": "e8ebdd68-1062-430f-81eb-2d43f30f4df7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x=np.array(Xtrain), y=ytrain, validation_data=(np.array(Xtest), ytest), batch_size=256, epochs=100, verbose=1)\n"
      ],
      "metadata": {
        "id": "z6-1bjm05jXU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cc8c746a-8f94-4c75-8aea-072d7c5a8d09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 62s 62s/step - loss: 1.4438 - accuracy: 0.4500 - val_loss: 24.0666 - val_accuracy: 0.5000\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 55s 55s/step - loss: 57.1534 - accuracy: 0.6750 - val_loss: 5.6427 - val_accuracy: 0.7000\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 55s 55s/step - loss: 57.1743 - accuracy: 0.7250 - val_loss: 39.5322 - val_accuracy: 0.6000\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 55s 55s/step - loss: 73.5232 - accuracy: 0.5500 - val_loss: 62.1171 - val_accuracy: 0.5000\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 56s 56s/step - loss: 79.4427 - accuracy: 0.6500 - val_loss: 11.1722 - val_accuracy: 0.7000\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 55s 55s/step - loss: 65.0258 - accuracy: 0.6500 - val_loss: 5.4862 - val_accuracy: 0.8000\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 55s 55s/step - loss: 42.2912 - accuracy: 0.7750 - val_loss: 24.4856 - val_accuracy: 0.7000\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 55s 55s/step - loss: 116.3276 - accuracy: 0.7500 - val_loss: 29.0264 - val_accuracy: 0.7000\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 55s 55s/step - loss: 42.2095 - accuracy: 0.7750 - val_loss: 34.0625 - val_accuracy: 0.6000\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 55s 55s/step - loss: 19.5104 - accuracy: 0.8750 - val_loss: 42.5389 - val_accuracy: 0.7000\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 55s 55s/step - loss: 55.2249 - accuracy: 0.8000 - val_loss: 30.8000 - val_accuracy: 0.8000\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 55s 55s/step - loss: 50.0074 - accuracy: 0.7750 - val_loss: 14.5722 - val_accuracy: 0.8000\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 55s 55s/step - loss: 20.9089 - accuracy: 0.8500 - val_loss: 4.0214 - val_accuracy: 0.9000\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 55s 55s/step - loss: 17.7119 - accuracy: 0.8750 - val_loss: 0.5737 - val_accuracy: 0.9000\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 55s 55s/step - loss: 11.1732 - accuracy: 0.9500 - val_loss: 2.9697 - val_accuracy: 0.9000\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 55s 55s/step - loss: 88.4860 - accuracy: 0.7250 - val_loss: 4.8125 - val_accuracy: 0.9000\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 55s 55s/step - loss: 24.8742 - accuracy: 0.8500 - val_loss: 6.5015 - val_accuracy: 0.9000\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 55s 55s/step - loss: 7.7467 - accuracy: 0.9500 - val_loss: 8.6956 - val_accuracy: 0.9000\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 55s 55s/step - loss: 22.0791 - accuracy: 0.8750 - val_loss: 10.0266 - val_accuracy: 0.9000\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 55s 55s/step - loss: 60.0899 - accuracy: 0.8500 - val_loss: 10.6686 - val_accuracy: 0.9000\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 55s 55s/step - loss: 18.1020 - accuracy: 0.8250 - val_loss: 9.8341 - val_accuracy: 0.9000\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 55s 55s/step - loss: 13.9348 - accuracy: 0.9500 - val_loss: 9.2082 - val_accuracy: 0.9000\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 55s 55s/step - loss: 0.5222 - accuracy: 0.9750 - val_loss: 8.7169 - val_accuracy: 0.9000\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 55s 55s/step - loss: 3.1377 - accuracy: 0.9750 - val_loss: 8.7256 - val_accuracy: 0.9000\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 55s 55s/step - loss: 1.1204 - accuracy: 0.9750 - val_loss: 8.7988 - val_accuracy: 0.9000\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 55s 55s/step - loss: 25.5159 - accuracy: 0.9500 - val_loss: 8.8396 - val_accuracy: 0.9000\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 55s 55s/step - loss: 2.7547 - accuracy: 0.9750 - val_loss: 9.1570 - val_accuracy: 0.9000\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 55s 55s/step - loss: 6.0631 - accuracy: 0.9500 - val_loss: 9.0076 - val_accuracy: 0.9000\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 55s 55s/step - loss: 17.0514 - accuracy: 0.9500 - val_loss: 8.7935 - val_accuracy: 0.9000\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 55s 55s/step - loss: 19.6652 - accuracy: 0.9000 - val_loss: 9.1049 - val_accuracy: 0.9000\n",
            "Epoch 31/100\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-68-c2240f955ff3>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Save the model using pickle\n",
        "with open('model2.pkl', 'wb') as f:\n",
        "    pickle.dump(model, f)\n"
      ],
      "metadata": {
        "id": "U6vtiw1p7Ey7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "source_file_path = 'model.pkl'\n",
        "\n",
        "destination_folder_path = '/content/drive/My Drive/Colab Notebooks/'\n",
        "\n",
        "shutil.copy(source_file_path, destination_folder_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "c3VrAKrkHbrj",
        "outputId": "499fd1af-9e89-42db-8b0d-34767690f673"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/Colab Notebooks/model.pkl'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "source_file_path = 'model2.pkl'\n",
        "\n",
        "destination_folder_path = '/content/drive/My Drive/Colab Notebooks/'\n",
        "\n",
        "shutil.copy(source_file_path, destination_folder_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "HqHrsHp9HqtA",
        "outputId": "22b21205-6de1-4e6e-badc-e098de9c1f29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/Colab Notebooks/model2.pkl'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "\n",
        "S = X.shape[0]\n",
        "L = X.shape[1]\n",
        "output_units = 1\n",
        "\n",
        "# Load ResNet50 without the top layer\n",
        "resnet = ResNet50(include_top=False, input_shape=(L, L, 3))\n",
        "\n",
        "# Freeze the pre-trained layers\n",
        "for layer in resnet.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Flatten the output of ResNet\n",
        "flatten = Flatten()(resnet.output)\n",
        "\n",
        "# Add Dense layers for custom classification\n",
        "dense1 = Dense(units=64, activation='relu')(flatten)\n",
        "dropout1 = Dropout(0.4)(dense1)\n",
        "dense2 = Dense(units=32, activation='relu')(dropout1)\n",
        "dropout2 = Dropout(0.4)(dense2)\n",
        "output_layer = Dense(units=output_units, activation='sigmoid')(dropout2)\n",
        "\n",
        "# Define the model\n",
        "model = Model(inputs=resnet.input, outputs=output_layer)\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fBcI5_gAFZo",
        "outputId": "97450508-df8a-45ef-e634-8583fe5b332e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_8\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_12 (InputLayer)       [(None, 1024, 1024, 3)]      0         []                            \n",
            "                                                                                                  \n",
            " conv1_pad (ZeroPadding2D)   (None, 1030, 1030, 3)        0         ['input_12[0][0]']            \n",
            "                                                                                                  \n",
            " conv1_conv (Conv2D)         (None, 512, 512, 64)         9472      ['conv1_pad[0][0]']           \n",
            "                                                                                                  \n",
            " conv1_bn (BatchNormalizati  (None, 512, 512, 64)         256       ['conv1_conv[0][0]']          \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv1_relu (Activation)     (None, 512, 512, 64)         0         ['conv1_bn[0][0]']            \n",
            "                                                                                                  \n",
            " pool1_pad (ZeroPadding2D)   (None, 514, 514, 64)         0         ['conv1_relu[0][0]']          \n",
            "                                                                                                  \n",
            " pool1_pool (MaxPooling2D)   (None, 256, 256, 64)         0         ['pool1_pad[0][0]']           \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2  (None, 256, 256, 64)         4160      ['pool1_pool[0][0]']          \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNo  (None, 256, 256, 64)         256       ['conv2_block1_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activ  (None, 256, 256, 64)         0         ['conv2_block1_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2  (None, 256, 256, 64)         36928     ['conv2_block1_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_bn (BatchNo  (None, 256, 256, 64)         256       ['conv2_block1_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block1_2_relu (Activ  (None, 256, 256, 64)         0         ['conv2_block1_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block1_0_conv (Conv2  (None, 256, 256, 256)        16640     ['pool1_pool[0][0]']          \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_3_conv (Conv2  (None, 256, 256, 256)        16640     ['conv2_block1_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_0_bn (BatchNo  (None, 256, 256, 256)        1024      ['conv2_block1_0_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block1_3_bn (BatchNo  (None, 256, 256, 256)        1024      ['conv2_block1_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block1_add (Add)      (None, 256, 256, 256)        0         ['conv2_block1_0_bn[0][0]',   \n",
            "                                                                     'conv2_block1_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv2_block1_out (Activati  (None, 256, 256, 256)        0         ['conv2_block1_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2  (None, 256, 256, 64)         16448     ['conv2_block1_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNo  (None, 256, 256, 64)         256       ['conv2_block2_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activ  (None, 256, 256, 64)         0         ['conv2_block2_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2  (None, 256, 256, 64)         36928     ['conv2_block2_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_bn (BatchNo  (None, 256, 256, 64)         256       ['conv2_block2_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block2_2_relu (Activ  (None, 256, 256, 64)         0         ['conv2_block2_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block2_3_conv (Conv2  (None, 256, 256, 256)        16640     ['conv2_block2_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_3_bn (BatchNo  (None, 256, 256, 256)        1024      ['conv2_block2_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block2_add (Add)      (None, 256, 256, 256)        0         ['conv2_block1_out[0][0]',    \n",
            "                                                                     'conv2_block2_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv2_block2_out (Activati  (None, 256, 256, 256)        0         ['conv2_block2_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2  (None, 256, 256, 64)         16448     ['conv2_block2_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNo  (None, 256, 256, 64)         256       ['conv2_block3_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activ  (None, 256, 256, 64)         0         ['conv2_block3_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2  (None, 256, 256, 64)         36928     ['conv2_block3_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_bn (BatchNo  (None, 256, 256, 64)         256       ['conv2_block3_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block3_2_relu (Activ  (None, 256, 256, 64)         0         ['conv2_block3_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block3_3_conv (Conv2  (None, 256, 256, 256)        16640     ['conv2_block3_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_3_bn (BatchNo  (None, 256, 256, 256)        1024      ['conv2_block3_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block3_add (Add)      (None, 256, 256, 256)        0         ['conv2_block2_out[0][0]',    \n",
            "                                                                     'conv2_block3_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv2_block3_out (Activati  (None, 256, 256, 256)        0         ['conv2_block3_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2  (None, 128, 128, 128)        32896     ['conv2_block3_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNo  (None, 128, 128, 128)        512       ['conv3_block1_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activ  (None, 128, 128, 128)        0         ['conv3_block1_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2  (None, 128, 128, 128)        147584    ['conv3_block1_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_bn (BatchNo  (None, 128, 128, 128)        512       ['conv3_block1_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block1_2_relu (Activ  (None, 128, 128, 128)        0         ['conv3_block1_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block1_0_conv (Conv2  (None, 128, 128, 512)        131584    ['conv2_block3_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_3_conv (Conv2  (None, 128, 128, 512)        66048     ['conv3_block1_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_0_bn (BatchNo  (None, 128, 128, 512)        2048      ['conv3_block1_0_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block1_3_bn (BatchNo  (None, 128, 128, 512)        2048      ['conv3_block1_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block1_add (Add)      (None, 128, 128, 512)        0         ['conv3_block1_0_bn[0][0]',   \n",
            "                                                                     'conv3_block1_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block1_out (Activati  (None, 128, 128, 512)        0         ['conv3_block1_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2  (None, 128, 128, 128)        65664     ['conv3_block1_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNo  (None, 128, 128, 128)        512       ['conv3_block2_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activ  (None, 128, 128, 128)        0         ['conv3_block2_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2  (None, 128, 128, 128)        147584    ['conv3_block2_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_bn (BatchNo  (None, 128, 128, 128)        512       ['conv3_block2_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block2_2_relu (Activ  (None, 128, 128, 128)        0         ['conv3_block2_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block2_3_conv (Conv2  (None, 128, 128, 512)        66048     ['conv3_block2_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_3_bn (BatchNo  (None, 128, 128, 512)        2048      ['conv3_block2_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block2_add (Add)      (None, 128, 128, 512)        0         ['conv3_block1_out[0][0]',    \n",
            "                                                                     'conv3_block2_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block2_out (Activati  (None, 128, 128, 512)        0         ['conv3_block2_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2  (None, 128, 128, 128)        65664     ['conv3_block2_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNo  (None, 128, 128, 128)        512       ['conv3_block3_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activ  (None, 128, 128, 128)        0         ['conv3_block3_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2  (None, 128, 128, 128)        147584    ['conv3_block3_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_bn (BatchNo  (None, 128, 128, 128)        512       ['conv3_block3_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block3_2_relu (Activ  (None, 128, 128, 128)        0         ['conv3_block3_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block3_3_conv (Conv2  (None, 128, 128, 512)        66048     ['conv3_block3_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_3_bn (BatchNo  (None, 128, 128, 512)        2048      ['conv3_block3_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block3_add (Add)      (None, 128, 128, 512)        0         ['conv3_block2_out[0][0]',    \n",
            "                                                                     'conv3_block3_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block3_out (Activati  (None, 128, 128, 512)        0         ['conv3_block3_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2  (None, 128, 128, 128)        65664     ['conv3_block3_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNo  (None, 128, 128, 128)        512       ['conv3_block4_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activ  (None, 128, 128, 128)        0         ['conv3_block4_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2  (None, 128, 128, 128)        147584    ['conv3_block4_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_bn (BatchNo  (None, 128, 128, 128)        512       ['conv3_block4_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block4_2_relu (Activ  (None, 128, 128, 128)        0         ['conv3_block4_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block4_3_conv (Conv2  (None, 128, 128, 512)        66048     ['conv3_block4_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_3_bn (BatchNo  (None, 128, 128, 512)        2048      ['conv3_block4_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block4_add (Add)      (None, 128, 128, 512)        0         ['conv3_block3_out[0][0]',    \n",
            "                                                                     'conv3_block4_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block4_out (Activati  (None, 128, 128, 512)        0         ['conv3_block4_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2  (None, 64, 64, 256)          131328    ['conv3_block4_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNo  (None, 64, 64, 256)          1024      ['conv4_block1_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activ  (None, 64, 64, 256)          0         ['conv4_block1_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2  (None, 64, 64, 256)          590080    ['conv4_block1_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_bn (BatchNo  (None, 64, 64, 256)          1024      ['conv4_block1_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block1_2_relu (Activ  (None, 64, 64, 256)          0         ['conv4_block1_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block1_0_conv (Conv2  (None, 64, 64, 1024)         525312    ['conv3_block4_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_3_conv (Conv2  (None, 64, 64, 1024)         263168    ['conv4_block1_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_0_bn (BatchNo  (None, 64, 64, 1024)         4096      ['conv4_block1_0_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block1_3_bn (BatchNo  (None, 64, 64, 1024)         4096      ['conv4_block1_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block1_add (Add)      (None, 64, 64, 1024)         0         ['conv4_block1_0_bn[0][0]',   \n",
            "                                                                     'conv4_block1_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block1_out (Activati  (None, 64, 64, 1024)         0         ['conv4_block1_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2  (None, 64, 64, 256)          262400    ['conv4_block1_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNo  (None, 64, 64, 256)          1024      ['conv4_block2_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activ  (None, 64, 64, 256)          0         ['conv4_block2_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2  (None, 64, 64, 256)          590080    ['conv4_block2_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_bn (BatchNo  (None, 64, 64, 256)          1024      ['conv4_block2_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block2_2_relu (Activ  (None, 64, 64, 256)          0         ['conv4_block2_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block2_3_conv (Conv2  (None, 64, 64, 1024)         263168    ['conv4_block2_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_3_bn (BatchNo  (None, 64, 64, 1024)         4096      ['conv4_block2_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block2_add (Add)      (None, 64, 64, 1024)         0         ['conv4_block1_out[0][0]',    \n",
            "                                                                     'conv4_block2_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block2_out (Activati  (None, 64, 64, 1024)         0         ['conv4_block2_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2  (None, 64, 64, 256)          262400    ['conv4_block2_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNo  (None, 64, 64, 256)          1024      ['conv4_block3_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activ  (None, 64, 64, 256)          0         ['conv4_block3_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2  (None, 64, 64, 256)          590080    ['conv4_block3_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_bn (BatchNo  (None, 64, 64, 256)          1024      ['conv4_block3_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block3_2_relu (Activ  (None, 64, 64, 256)          0         ['conv4_block3_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block3_3_conv (Conv2  (None, 64, 64, 1024)         263168    ['conv4_block3_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_3_bn (BatchNo  (None, 64, 64, 1024)         4096      ['conv4_block3_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block3_add (Add)      (None, 64, 64, 1024)         0         ['conv4_block2_out[0][0]',    \n",
            "                                                                     'conv4_block3_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block3_out (Activati  (None, 64, 64, 1024)         0         ['conv4_block3_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2  (None, 64, 64, 256)          262400    ['conv4_block3_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNo  (None, 64, 64, 256)          1024      ['conv4_block4_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activ  (None, 64, 64, 256)          0         ['conv4_block4_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2  (None, 64, 64, 256)          590080    ['conv4_block4_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_bn (BatchNo  (None, 64, 64, 256)          1024      ['conv4_block4_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block4_2_relu (Activ  (None, 64, 64, 256)          0         ['conv4_block4_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block4_3_conv (Conv2  (None, 64, 64, 1024)         263168    ['conv4_block4_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_3_bn (BatchNo  (None, 64, 64, 1024)         4096      ['conv4_block4_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block4_add (Add)      (None, 64, 64, 1024)         0         ['conv4_block3_out[0][0]',    \n",
            "                                                                     'conv4_block4_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block4_out (Activati  (None, 64, 64, 1024)         0         ['conv4_block4_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2  (None, 64, 64, 256)          262400    ['conv4_block4_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNo  (None, 64, 64, 256)          1024      ['conv4_block5_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activ  (None, 64, 64, 256)          0         ['conv4_block5_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2  (None, 64, 64, 256)          590080    ['conv4_block5_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_bn (BatchNo  (None, 64, 64, 256)          1024      ['conv4_block5_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block5_2_relu (Activ  (None, 64, 64, 256)          0         ['conv4_block5_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block5_3_conv (Conv2  (None, 64, 64, 1024)         263168    ['conv4_block5_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_3_bn (BatchNo  (None, 64, 64, 1024)         4096      ['conv4_block5_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block5_add (Add)      (None, 64, 64, 1024)         0         ['conv4_block4_out[0][0]',    \n",
            "                                                                     'conv4_block5_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block5_out (Activati  (None, 64, 64, 1024)         0         ['conv4_block5_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2  (None, 64, 64, 256)          262400    ['conv4_block5_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNo  (None, 64, 64, 256)          1024      ['conv4_block6_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activ  (None, 64, 64, 256)          0         ['conv4_block6_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2  (None, 64, 64, 256)          590080    ['conv4_block6_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_bn (BatchNo  (None, 64, 64, 256)          1024      ['conv4_block6_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block6_2_relu (Activ  (None, 64, 64, 256)          0         ['conv4_block6_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block6_3_conv (Conv2  (None, 64, 64, 1024)         263168    ['conv4_block6_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_3_bn (BatchNo  (None, 64, 64, 1024)         4096      ['conv4_block6_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block6_add (Add)      (None, 64, 64, 1024)         0         ['conv4_block5_out[0][0]',    \n",
            "                                                                     'conv4_block6_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block6_out (Activati  (None, 64, 64, 1024)         0         ['conv4_block6_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2  (None, 32, 32, 512)          524800    ['conv4_block6_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNo  (None, 32, 32, 512)          2048      ['conv5_block1_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activ  (None, 32, 32, 512)          0         ['conv5_block1_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2  (None, 32, 32, 512)          2359808   ['conv5_block1_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_bn (BatchNo  (None, 32, 32, 512)          2048      ['conv5_block1_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block1_2_relu (Activ  (None, 32, 32, 512)          0         ['conv5_block1_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block1_0_conv (Conv2  (None, 32, 32, 2048)         2099200   ['conv4_block6_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_3_conv (Conv2  (None, 32, 32, 2048)         1050624   ['conv5_block1_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_0_bn (BatchNo  (None, 32, 32, 2048)         8192      ['conv5_block1_0_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block1_3_bn (BatchNo  (None, 32, 32, 2048)         8192      ['conv5_block1_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block1_add (Add)      (None, 32, 32, 2048)         0         ['conv5_block1_0_bn[0][0]',   \n",
            "                                                                     'conv5_block1_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block1_out (Activati  (None, 32, 32, 2048)         0         ['conv5_block1_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2  (None, 32, 32, 512)          1049088   ['conv5_block1_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNo  (None, 32, 32, 512)          2048      ['conv5_block2_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activ  (None, 32, 32, 512)          0         ['conv5_block2_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2  (None, 32, 32, 512)          2359808   ['conv5_block2_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_bn (BatchNo  (None, 32, 32, 512)          2048      ['conv5_block2_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block2_2_relu (Activ  (None, 32, 32, 512)          0         ['conv5_block2_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block2_3_conv (Conv2  (None, 32, 32, 2048)         1050624   ['conv5_block2_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_3_bn (BatchNo  (None, 32, 32, 2048)         8192      ['conv5_block2_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block2_add (Add)      (None, 32, 32, 2048)         0         ['conv5_block1_out[0][0]',    \n",
            "                                                                     'conv5_block2_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block2_out (Activati  (None, 32, 32, 2048)         0         ['conv5_block2_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2  (None, 32, 32, 512)          1049088   ['conv5_block2_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNo  (None, 32, 32, 512)          2048      ['conv5_block3_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activ  (None, 32, 32, 512)          0         ['conv5_block3_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2  (None, 32, 32, 512)          2359808   ['conv5_block3_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_bn (BatchNo  (None, 32, 32, 512)          2048      ['conv5_block3_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block3_2_relu (Activ  (None, 32, 32, 512)          0         ['conv5_block3_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block3_3_conv (Conv2  (None, 32, 32, 2048)         1050624   ['conv5_block3_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_3_bn (BatchNo  (None, 32, 32, 2048)         8192      ['conv5_block3_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block3_add (Add)      (None, 32, 32, 2048)         0         ['conv5_block2_out[0][0]',    \n",
            "                                                                     'conv5_block3_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block3_out (Activati  (None, 32, 32, 2048)         0         ['conv5_block3_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " flatten_8 (Flatten)         (None, 2097152)              0         ['conv5_block3_out[0][0]']    \n",
            "                                                                                                  \n",
            " dense_24 (Dense)            (None, 64)                   1342177   ['flatten_8[0][0]']           \n",
            "                                                          92                                      \n",
            "                                                                                                  \n",
            " dropout_16 (Dropout)        (None, 64)                   0         ['dense_24[0][0]']            \n",
            "                                                                                                  \n",
            " dense_25 (Dense)            (None, 32)                   2080      ['dropout_16[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_17 (Dropout)        (None, 32)                   0         ['dense_25[0][0]']            \n",
            "                                                                                                  \n",
            " dense_26 (Dense)            (None, 1)                    33        ['dropout_17[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 157807617 (601.99 MB)\n",
            "Trainable params: 134219905 (512.01 MB)\n",
            "Non-trainable params: 23587712 (89.98 MB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}